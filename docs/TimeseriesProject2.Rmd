---
title: "Alfonso Andres Time Series Project"
author: "Alfonso Andres"
date: "2023-07-10"
output:
  html_document: default
  pdf_document: default
---
## Introduction
This project involves fitting various time series models to multiple datasets to explore patterns and predict complex outcomes. We will work with six distinct datasets, analyzing each using different time series methodologies. By comparing the results, we will highlight the strengths and weaknesses of each approach in time series analysis.

First of all show all the libraries to we will use in this project.
Most of them have been seen in class
```{r}
library('ggfortify')
library('ggplot2')
library('stats')
library("dlm")
library('forecast')
library('bsts')
library('nnet')
```
## Part 1: Alcoa Stocks
In this analysis, we use the dataset aa-rv-20m.txt, which contains the realized daily volatility series of Alcoa stock returns. The data spans from January 2, 2003, to May 7, 2004, and is based on 20-minute intraday log returns. The primary goal is to model and analyze the log-transformed volatility series using two different approaches.
After calling the necessary libraries. We open the dataset as a csv file and plot the Alcoa stocks as a Time series with  no seasonal component.

We fit the ARIMA(0,1,1) model to our data, and plot fitted values as the observed values plus the residuals that have just been obtained from the process.
It is known that the ARIMA(0,1,1), as every other ARIMA process, is equivalent to a state-space model with the following equation: 
$y_{t}=\mu_{t}-\epsilon{t} \;\;\; \epsilon\sim N(0,\sigma_{\epsilon})$
$\mu_{t+1}=\mu_{t}+ \eta{t}\;\;\; \eta\sim N(0,\sigma_{\eta})$

We plot the fitted value and see a significant different in the fitted values from the model than in the observed. We are now going to see whethere the the residuals follow a normal distribution and also the goodness of fit


```{r}
www <- 'https://www.mimuw.edu.pl/~noble/courses/TimeSeries/data/aa-rv-20m.txt'
df1 <- read.csv(www)
dfts <- ts(df1)
arimadf <- arima(dfts,order = c(0,1,1))
plot(dfts, ylab = 'stock value', xlab = 'day',mai = 'Alcoa Stock ')
lines(arimadf$residuals+dfts,col = 'seagreen')
```
As we can see residuals do not follow a normal distribution judging this qq plot. 

```{r}
qqnorm(arimadf$residuals,col='blue',pch = 19,main = 'Normal Q-Q for the regression of ARIMA(0,1,1) residuals')
qqline(arimadf$residuals,col ='red',lwd=3)
```

Interpreting the AIC we can see that is not a really explicative model for our data since by the AIC criterion our value is really high.
We see that the mean is relatively low compared to the logarithmic values of our dataset. However the variance is extremely high and so the value vary abrouptly and the fit of the model is not too good
```{r}
cat(var(arimadf$residuals),mean(arimadf$residuals),arimadf$aic)

```
We use the package Struct TS to get the respective variances through the value of each.
$\sigma_{\epsilon}= 4,9$
$\sigma_{\eta}=0.017007 $
The variance of the measurement error is a lot smaller, so the  model is well adjusted for this parameters and the second-level equation.
```{r}
structure <-StructTS(dfts,type = 'level')
structure$coef
```
We now plot the filtered and smoothed variables with 95% pointwise confidence interval.
The scatter plot does not give a clear outcome since the amount of data is big and there scatter is all piled up.However we see that in both cases the filtered and smoothed data is generally closer to 0 than the observed, so there is lower presence of outliers.
The confidence interval is not too big either so it is a good estimation taking into account that the innovation variance for either case and time period is almost constant and subsequently small.


```{r}
modi <-dlmModPoly(1)
modi$C0<-1
stockfilter <- dlmFilter(dfts,modi)
stocksmoother<- dlmSmooth(dfts, modi) 
plot(dfts,type = 'l', col = 'black',lwd = 1.9, main ='Kalman filtering with a 95% conf. interval')
lines(dropFirst(stockfilter$m), type = 'o', pch = 20, col = "blue")
attach(stockfilter)
v <- unlist(dlmSvd2var(U.C, D.C))
pl <-  stockfilter$m + qnorm(0.05, sd = sqrt(v))
pu <-    stockfilter$m + qnorm(0.95, sd = sqrt(v))
detach(stockfilter)
lines(pl, lty = 2, col = "blue")
lines(pu, lty = 2, col = "blue")
legend(1,20,legend=c('Observations','Filtered data','Confidence interval'),
       col =c('black','blue','blue'),lty =c(1,1,2))

```
```{r}
plot(dfts,type = 'l', col = 'black',lwd = 1.9, 
     main ='Smoothed observations with a 95%conf interval')

lines(dropFirst(stocksmoother$s), type = 'o', pch = 20, col = "seagreen")
attach(stocksmoother)
sl <-  stocksmoother$s + qnorm(0.05, sd = sqrt(s))
su <-  stocksmoother$s +qnorm(0.95, sd = sqrt(s))
detach()
lines(sl, lty = 2, col = "seagreen")
lines(su, lty = 2, col = "seagreen")
legend(1,20,legend=c('Observations','Smoothed data','95%Confidence interval'),
       col =c('black','seagreen','seagreen'),lty =c(1,1,2))

```
##Part 2: Pfizer data
In this part we wil use monthly simple excess returns of Pfizer stock and the S&P 500 composite index from
January 1990 to December 2003. The excess returns are in m-pfesp-ex9003.txt with Pfizer stock
returns in the first column.

First we open our data and plot both columns. Pfizer stocks and S&P 500 returns. The data spreads evenly around the values $[-0.1,0.1]$ for the Pfizer stocks and $[-0.10,0.10]$ in the other column, with a couple of outliers in either case.
```{r}
www1 <- 'https://www.mimuw.edu.pl/~noble/courses/TimeSeries/data/m-pfesp-ex9003.txt'
names <-c('Pfizer','S&P500')
pfizer <- read.csv(www1,sep = '',header = FALSE,col.names = names)
pfizerts<-ts(pfizer,frequency = 12,start = 1990)
plot(pfizerts,type = 'b', col= c('red'),pch = 19, main= 'Pfizer and S.P 500')
```

For a constant coefficient model we are going to fit an ARIMA(p,q,d) and fit the Pfizer returns. 
With the auto.arima function we can see for what values the observed data gets a best fit and check the goodness of fit.
In this case we see that the best option is an ARIMA(0,0,1) this is equivalent to a MA(1) process. Where the equation is $y_{t} = \mu + \epsilon{t} + \theta_{1} \epsilon_{t-1} $
The outcome of the coefficients are $\mu = 0.0158 \;\;\; \theta_{1} = -0.1035$
We see that the AIC criterion is low by our standards, but we will check further if the model is indeed good. 
Judging by the RMSE of the training set the model is very descriptive. Values of the ME are also low which gives a good outcome in various criterion so the model is successfully fitted
```{r}
autopfizer <-auto.arima(pfizer$Pfizer)
autopfizer
summary(autopfizer)
```

However when plotting the fitted model vs the initially observed data we can see a much higher variance in the ARIMA(0,0,1) process. Still the fit is more than acceptable and the study is successful.
```{r}
plot(autopfizer$residuals + pfizer$Pfizer)
lines(pfizer$Pfizer, col = 'cadetblue3',type = 'b',pch = 19)
```

Now we will fit a state-space model to our data.
$y_{t}=F_{t}\mu_{t}+V_{t}\epsilon{t} \;\;\; \epsilon\sim N(0,\sigma_{\epsilon})$
$\mu_{t+1}=G_{t}\mu_{t}+ W_{t}\eta{t}\;\;\; \eta\sim N(0,\sigma_{\eta})$
In this particular case we fit the model with the following parameters :
$V_{t},W_{t} = 1 \;\; t \in 1,2,....,n$
$G_{t},F_{t},W_{t} = I$ I being the identity matrix.
So our equation system looks like this a CAPM model that we can fit.
After fitting the model we get the innovation variances for each different time.
As we see there is not many variations either in the smoothed data or the variances themselves since they are all pretty much the same value.
We also plotted the smoothed data for all the $\alpha_{t} \;\;\;and\;\;\;\beta_{t}$.
We see that the $\alpha$ takes much more plain values in comparison to our other state variable.
Our observed data varies unevenly along the axis similarly to $\beta$

```{r}
CAPM <-dlmModPoly(2)
CAPM$FF<-CAPM$GG<-CAPM$W<-diag(2)
reg <-dlmSmooth(pfizer$Pfizer,CAPM)
reg$D.S
```
```{r}
plot(reg$s[,2],main = 'Smoothed values of alpha and betha',type = 'l', ylab = 'pfizer stock value')
lines(reg$s[,1], col = 'cadetblue3', lwd = 3)
lines(pfizer$Pfizer,col = 'orange')
legend(60,0.20,c('beta','alpha','Observed data'),col =c('black','cadetblue3','orange'),lty =c(1,1,1))
```
##Part 3: U.S PPI index
The file "m-ppiaco4709.txt" contains year, month, day, and U.S. producer price index (PPI) from
January 1947 to November 2009 that we will use to fit our AR(p) model
We proceed to the reading and processing of our data. First take the observed data $Z_{t}\;\;\;t\in{1,2,3,....,n}$ and transform it first by doing $z_{t} = ln(Z_{t})-ln(Z_{t-1})$ and then by centering all the data on the mean by $y_{t} = z_{t}-\hat{z_{t}}$
```{r}
ww2 = 'https://www.mimuw.edu.pl/~noble/courses/TimeSeries/data/m-ppiaco4709.txt'
ppindex <- read.csv(ww2,sep = '', col.names = c('year','month','day','ppi'))
ppindexts <-ts(ppindex$ppi,frequency = 12, start = 1947)
plot(ppindexts,pch = 20, type = 'l', main = 'PPINDEX TRAJECTORY')
lines(ppindexts,col = 'blue')
ppindexlog<-diff(log(ppindexts))
ppindexlog2<-diff(log(ppindex$ppi))
meanppi <- mean(ppindexlog2)
lines(ppindexlog)
yt  <-ppindexlog-meanppi

```
We see a clear difference in the trajectory of both variables, basically because one is focused on the variance in comparison to the previous year and the other in the trajectory through out the last 60 years of the PP index.

```{r}
plot(yt,col ='seagreen')

```

Now we fit the model that was asked in the exercise, an AR(3) model to fit the data. Already knowing that all AR(p) models can b expressed as state-space model we could also fit this model using the dlm package (which we will do after).
We check the AIC criterion and the outcome is not too good, however our coefficients are not too high and the RMSE is low still which could mean that the model is well fiutted for our tranformed data $y_{t}$. Also the ME of our training set seems low another indicative of a good AR(3).

```{r}
arimayt<- arima(yt,order = c(3,0,0))
summary(arimayt)

```
We see that the AR(3) model distances a little from our observed data, however the same happened in the previous exercise and the process was highly significant

```{r}
plot(yt + arimayt$residuals)
lines(yt, col='seagreen')

```

The variance and mean of the errors are low. $Y_{t}$ had 0 mean which means that a good fit would have something really close to 0, also the variance of the residuals is low which means that they do not fall to far off of their mean.
```{r}
cat(var(arimayt$residuals),mean(arimayt$residuals))

```
To use a state space form to estimate the parameters with the observation equation as: $y_{t}= x_{t} + \epsilon{t} \;\;\; \epsilon\sim N(0,\sigma_{\epsilon})\;$. Knowing that $x_{t}$ is an AR(3) model, we have to carve the space state equations to fit the model

First of all the general space-state equations are:
$y_{t}= F{t} \alpha_{t} + S_{t}\epsilon{t} \;\;\; \epsilon{t}\sim N(0,\sigma_{\epsilon})\;$
$\alpha_{t+1}= G{t} \alpha_{t} + V_{t}\nu{t} \;\;\; \nu_{t}\sim N(0,\sigma_{\nu})\;$
In this case we have to transform G into a $I_{3}$ matrix in order to fit the model all other parameters stay the same i.e $F_{t},S_{t},V_{t} = 1$.
Therefore our final equation shapes like :
$y_{t}= F{t} \alpha_{t} + S_{t}\epsilon{t} \;\;\; \epsilon{t}\sim N(0,\sigma_{\epsilon})\;$
$\alpha_{t+1}=  \theta_{1}\alpha_{t} +\theta_{2}\alpha_{t-1}+\theta_{3}\alpha_{t-2} + \nu{t} \;\;\; \nu_{t}\sim N(0,\sigma_{\nu})\;$
Becoming the measurement equation into an AR(3) process.
We can either fit every constant $\theta_{i}$ or have them take the previously fitted AR(3) coefficients 


```{r}
mod3<-dlmModPoly(1)
mod3$GG<-c(vector <- c(2.865738e-01, 1.230560e-01, 9.048862e-02))
mod3

prodfilter <-dlmFilter(yt,mod3)
prodsmoothed<-dlmSmooth(yt,mod3)

error <- yt-prodfilter$m

plot(yt,type='l',col = 'darkorchid1', main = 'Filtered errors vs Observed values', ylab = 'PPI', xlab = 'Time') 
lines(error)
legend(1950,-0.02,,legend=c('Observations','Filtered AR errors'),
       col =c('darkorchid1','black'),lty=c(1,1))
```

When plotting the errors we see a clear resemblance to the observed data, it is because indirectly the filtered schema is indeed similar to the PPI index. We plot them together to see a comparison. The errors take much lower values as it was expected, since the filtered schema usually has a much more plain graph and fitness than the original observed sample
We also plot the innovation variances of the fitted model and they are constant, none of them surpass 1 and most are stuck at 0.8451779

```{r}
innvarf <- sqrt(prodfilter$D.C)
plot(innvarf[-1])
```

We get the sample variance $\hat{\sigma_{\epsilon}}$, an estimation of $\sigma_{\epsilon}=1.566156e-05$. Very low so the estimation seems decent.
```{r}
var(error)
```
Below we have the time plot of the smoothed data vs the observed data. As we can see the smoothed data distributes much more evenly along the axis and there is not 
```{r}
plot(yt, main ='Smoothed AR state space model',col = 'grey',ylab = 'PPI', xlab = 'Time')
lines(prodsmoothed$s,type='l',col = 'black',lwd = 1.9,,pch = 20)
legend(1950,0.04,,legend=c('Observations','Smoothed AR'),
       col =c('grey','black'),lty=c(1,1))
```
##Part 4: IBM stocks data
We now consider the simple returns of IBM stock, CRSP value-weighted index, CRSP equal-weighted index,
and the S&P composite index from January 1980 to December 2008.
After opening and checking the data, the exercise asks to perform a simple regression to see the effect of weekday trading at 5% confidence level.
I opted on using a simple regression function 'lm' and making the dependent variables every day of the week that appears. Apparently when we fit the regression we can see that the most significant days are Monday.Tuesday and Friday, Thursday does not seem to appear  due to the fact that it is linearly related to the other days of the week.
Therefore the most important values seem to be those.
The low p-value return infers that there is indeed evidence to reject the null hypothesis, so therefore there is significance in the relation of the weekday to the EW return.
```{r}
ww3 = 'https://www.mimuw.edu.pl/~noble/courses/TimeSeries/data/d-ibm3dxwkdays8008.txt'
ibmm<-read.csv(ww3,header = TRUE,sep = '',
               col.names = c('year', 'mom','day','ibm','vw','ew', 'sp', 'm','t','w','r' ,'f'))
regression<-lm(formula = ew ~ m+t+w+f+r,,data = ibmm)
summary(regression)
```

We check the ACF to see if there is indeed correlation in between the estimated errors. As we can see the correlation decreasing as the lags grow bigger. So if there is indeed correlation we can create a time series of the different correlations and plot it as we did.
Also we can create a time series of the residuals and fit an AR(1) model to them since the ACF at lag 1 is evidently much more significant than at other particular lags. Let's do it and check the goodness of fit.

```{r}
autocorr<-acf(regression$residuals, main ='Regression residuals ACF'  )
plot(autocorr,type='b', col = 'seagreen')
```

After checking the results we see the particularly small outcome of the coefficients, however the fit is not entirely good since the AIC criterion differs enormously from 0 and the MSE is not too small in comparison to the values of the exercise
```{r}
resreg<-arima(regression$residuals,c(1,0,0))
summary(resreg)

```
##Part 5: GE stocks
Consider the monthly simple returns of GE stock from January 1926 to December 2008.
In this exercise we are going to work with neural networks along with the forecasting of data. First of all we use the 'nnet' package, and in itÂ´s detfect nnet function to fit the 1-2-3 feedforward network with 3 input layers 2 hidden layers and one output layer.
Here is the summary of the fitted model with each coefficient for each layer. We get the 3 input layers as $i_{j}\,\,\; j \in 1,2,3$.
The data is prepared getting the lagged data x0,x1,x2 and then the network is fitted with x3; the last lagged value.

```{r}
ww4 = 'https://www.mimuw.edu.pl/~noble/courses/TimeSeries/data/m-ge2608.txt'
GE <-read.csv(ww4,sep = '')
x0=data.frame(GE$rtn)
x1=data.frame(GE[-1,2])
x2=data.frame(x1[-1,])
x3=data.frame(x2[-1,])
x = data.frame(cbind(x0[1:991,],x1[1:991,],x2[1:991,]))
neuro<-nnet(x,x3[1:991,],size = 2,linout=TRUE)
summary(neuro)
```
We get now the MSE from our neural network estimation. Using the prediction function. The MSE is large indeed so we conclude that the prediction estimation is bad.

```{r}
newdata_ = data.frame(cbind(x0[991:994,],x1[991:994,],x2[991:994,]))
pred = predict(neuro,newdata_)
mse <- sum((neuro$fitted.values-x0[1:991,])^2)
mse
```
However using the forecast and nntar functions we get a larger estimation and a better MSE for this particular case.
One step ahead forecasts we see that this function is rather more effective judging by the estimated MSE that finally is around
```{r}
nntar1<-nnetar(ts(x0),p=3,size=2)
fore1 <-forecast(nntar1)
mse2 <- sum((nntar1$fitted[4:996]-x0[4:996,])^2)
mse2
```

```{r}
fore1
```
We are now going to plot the forecast but with a slight change since we are only going to use a part of the dataframe in the plot and prediction. The number of observed data is to big and at the time of plotting the predicted data seems too small when you do it with the entire mass of GE stocks returns 1926-2008.
When plotting the results we see that the variation of the forecast seems a lot lower and that the prediction gets rather stuck and stable. This is probably due to the fact that the prediction is not too good, and also needs to be longer.
```{r}
nntar2<-nnetar(ts(x0[750:996,]),p=3,size=2)
fore2 <-forecast(nntar2)
plot(fore2)
```

Now we have to create a 6-5-1 forward feed neural network.
For that we create the 6 layer input though a lagged dataframe. Also we leave a couple of rows behind so that all the lagged GE stocks have the same size and for the later prediction.
We fit the process exactly how we fitted the one in the previous exercise. We get the subsequent layers and their values after fitting the neural network
```{r}
x4=data.frame(x3[-1,])
x5=data.frame(x4[-1,])
x6=data.frame(x5[-1,])
x<-cbind(x[1:990,],x4[1:990,],x5[1:990,])
neuro<-nnet(x[1:897,],x6[1:897,],size = 5,linout=TRUE)
summary(neuro)
```

Now we create a loop to transform the predicted values into a categorical variable that return a 1 if the forecast is supposed to increase and a 0 if it is supposed to decrease; just like the exercise urges to do.
Our result is a decrease in the first predicted value but an increase for the next five

```{r}
prediction<-predict(neuro,x[987:990,],linout = FALSE)

result <- numeric(length(prediction))
for (i in 2:length(prediction)) {
  if (prediction[i] > prediction[i-1]) {
    result[i] <- 1
  } else {
    result[i] <- 0
  }
}
result
```
##Part 6: US dollar-euro conversion$$

We are going to see two prediction methods. First of all however we have to see how our data behaves.
We plot the time series of U.S return in exchange for euro return.
Apparently that the return seems to be a lot lower around 2010, most probably because of the economical regression and had an increasing behavior up to mid 2011, then it became  more stable
```{r}
ww5<- 'https://www.mimuw.edu.pl/~noble/courses/TimeSeries/data/USunemp.dat'
usreturn<-read.csv(ww5)
tsusreturn <- ts(usreturn, frequency = 26,start = 2008)

plot(tsusreturn,pch = 20, main = 'U.S RETURN OVER 5 YEARS ')
```

Now we fit an ARIMA(p,q,d) process into the data and see the forecasted data.
The auto.arima function helps us select values p,d,q and in this particular case our outcome is (2,1,1) (taking into account that I set a maximum of 3 for all parameters)

Knowing that we forecast and plot the data with a [50,90] conf interval.
We see that the estimation is not too bad and could be performed since the model has a  general good fit by the criterion shown below (AIC AND RMSE), specially RMSE since the return is very low in comparison to the $y_{t}$ of the data
```{r}
autarima <- auto.arima(usreturn,max.p = 3,max.q =3 ,max.d = 3)
forearima<-  forecast(auto.arima(tsusreturn))
plot(forecast(auto.arima(tsusreturn),level=c(50,95)), sub = "Simple plot to forecast")
```
```{r}
summary(autarima)
```
We get a Mean Square Value of 2.044, it is not very significant since the other forecasting methods have not been depicted yet. Nevertheless we can see that compared to the observed data, around 6,5 all the time the error is not too big so it is a good forecast method
```{r}
msearima <-sum((forearima$fitted-tsusreturn)^2)
msearima
```
We can also use the predict method and compare the results with our forecasting data. Lets take a look into it.
We see that the forecast is not too elaborated, just a straight line that follows the previous plot, however the MSE return is just a little bit higher than our last MSE that we computed with the forecast function. Truly surprising if you think about it since this estimation seems a lot less accurate judging from the plot
```{r}
pred <- predict(autarima,ci = 0.95,n.ahead=40)
ts.plot(ts(usreturn),ts(pred$pred), log = "y", lty = c(1,3))

```
```{r}
fit <- StructTS(usreturn,type='level')
forespace<-forecast(fit)
plot(forecast(fit,h = 26,level = c(30,95), xlim = c(2013,2014)))
```

```{r}
msespace <-sum((forespace$fitted-ts(usreturn))^2)
msespace
```
Lets try now a function that has not been used in class for the second year of activity.
We can try on prediction the next few values or predicting directly the second year taking into account the first as it is asked in the exam.
We use it and check the performance via the mse. It is very satisfactory, we see that by plotting the results do not differ in more than 1 from the actual return of the US dollar for 2009 (year we are forecasting).
The AIC criterion also returns a low value and the results are satisfactory. We set the box cox attribute to NULL in order to use it or not, however the result is more accurate.
An MSE of 0.2 is extremely low, however is not comparable to the rest mainly because in the other cases we were using the entire data and here only year 1 and 2.
```{r}
fit <- tbats(tsusreturn[26:52],use.box.cox=NULL)
fit
```
```{r}
plot(forecast(fit),main = 'Forecast of second year U.S returns using Tbats', ylab = 'U.S returns',xlab = 'year quarter')


```
```{r}
msetbats<-sum((fitted(fit)-usreturn[26:52,1])^2)
msetbats

```
Lets do it now for the entire data and see the results with this new forecasting function from R. The result is not so satisfactory as before and computing the MSE we realized that the values are a little bit off
The size of the forecast has to be taking into perspective specially when judging goodness of fit parameters that is why comparing it to previous predictions. It is in between the first and the second. Meaning the simple forecasting from an ARIMA process seems like the best options for now.
We have to add that this function is based on an smoothed process so we just checked the validity of forecasting this piece of U.S returns using an smoothed process

```{r}
bats <- tbats(tsusreturn,use.box.cox=NULL)
bats
```
```{r}
plot(forecast(bats),main = 'Forecast of the entire U.S returns using Tbats')
```
```{r}
msebatss <- sum((fitted(bats)-tsusreturn)^2)
msebatss
```
Last but not least we are going to check the behavior of forecasting the data as a neural network. A simple 2 hidden layer feed forward n.n model.
For this model we are going to forecast the 2 year just from years before.
For example for $t = 29$ we predict with $t \in [1,28]$. In order to do it we loop over the nntar function and check for each return of the series. When comparing the series to our base U.S return we see that they are equivalent and so the forecast is COMPLETELY accurate if you do it on by one.
We are not able to compute the MSE, but it is 0 since both time series are equal
```{r}
forecast_values <- list()

for (i in 26:52) {
  # Apply the nnetar forecasting function
  forecast_result <- forecast(nnetar(tsusreturn[1:i], p = 1, size = 2))
  
  
  # Store the forecast value in the list
  forecast_values[[i - 25]] <- forecast_result
}


extract_first_values <- function(forecast_list) {
  # Create an empty vector to store the first values
  first_values <- vector()
  
  # Iterate over each sublist
  for (i in 1:length(forecast_list)) {
    # Extract the first value from the sublist and store it in the vector
    first_values[i] <- forecast_list[[i]][1]
  }
  
  # Return the vector of first values
  return(first_values[27])
}
forecast_method<-extract_first_values(forecast_values)
forecast_method

```

```{r}

tsusreturn[1:52]
```
